{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a36259be-4236-4a3e-b71e-4f1af5bebb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Copyright (c) 2012, Chi-En Wu\n",
    "from math import log\n",
    "\n",
    "def _normalize_prob(prob, item_set):\n",
    "    result = {}\n",
    "    if prob is None:\n",
    "        number = len(item_set)\n",
    "        for item in item_set:\n",
    "            result[item] = 1.0 / number\n",
    "    else:\n",
    "        prob_sum = 0.0\n",
    "        for item in item_set:\n",
    "            prob_sum += prob.get(item, 0)\n",
    "\n",
    "        if prob_sum > 0:\n",
    "            for item in item_set:\n",
    "                result[item] = prob.get(item, 0) / prob_sum\n",
    "        else:\n",
    "            for item in item_set:\n",
    "                result[item] = 0\n",
    "\n",
    "    return result\n",
    "\n",
    "def _normalize_prob_two_dim(prob, item_set1, item_set2):\n",
    "    result = {}\n",
    "    if prob is None:\n",
    "        for item in item_set1:\n",
    "            result[item] = _normalize_prob(None, item_set2)\n",
    "    else:\n",
    "        for item in item_set1:\n",
    "            result[item] = _normalize_prob(prob.get(item), item_set2)\n",
    "\n",
    "    return result\n",
    "\n",
    "def _count(item, count):\n",
    "    if item not in count:\n",
    "        count[item] = 0\n",
    "    count[item] += 1\n",
    "\n",
    "def _count_two_dim(item1, item2, count):\n",
    "    if item1 not in count:\n",
    "        count[item1] = {}\n",
    "    _count(item2, count[item1])\n",
    "\n",
    "def _get_init_model(sequences):\n",
    "    symbol_count = {}\n",
    "    state_count = {}\n",
    "    state_symbol_count = {}\n",
    "    state_start_count = {}\n",
    "    state_trans_count = {}\n",
    "\n",
    "    for state_list, symbol_list in sequences:\n",
    "        pre_state = None\n",
    "        for state, symbol in zip(state_list, symbol_list):\n",
    "            _count(state, state_count)\n",
    "            _count(symbol, symbol_count)\n",
    "            _count_two_dim(state, symbol, state_symbol_count)\n",
    "            if pre_state is None:\n",
    "                _count(state, state_start_count)\n",
    "            else:\n",
    "                _count_two_dim(pre_state, state, state_trans_count)\n",
    "            pre_state = state\n",
    "\n",
    "    return Model(state_count.keys(), symbol_count.keys(),\n",
    "        state_start_count, state_trans_count, state_symbol_count)\n",
    "\n",
    "def train(sequences, delta=0.0001, smoothing=0):\n",
    "    \"\"\"\n",
    "    Use the given sequences to train a HMM model.\n",
    "    This method is an implementation of the `EM algorithm\n",
    "    <http://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm>`_.\n",
    "    The `delta` argument (which is defaults to 0.0001) specifies that the\n",
    "    learning algorithm will stop when the difference of the log-likelihood\n",
    "    between two consecutive iterations is less than delta.\n",
    "    The `smoothing` argument is used to avoid zero probability,\n",
    "    see :py:meth:`~hmm.Model.learn`.\n",
    "    \"\"\"\n",
    "\n",
    "    model = _get_init_model(sequences)\n",
    "    length = len(sequences)\n",
    "\n",
    "    old_likelihood = 0\n",
    "    for _, symbol_list in sequences:\n",
    "        old_likelihood += log(model.evaluate(symbol_list))\n",
    "\n",
    "    old_likelihood /= length\n",
    "\n",
    "    while True:\n",
    "        new_likelihood = 0\n",
    "        for _, symbol_list in sequences:\n",
    "            model.learn(symbol_list, smoothing)\n",
    "            new_likelihood += log(model.evaluate(symbol_list))\n",
    "\n",
    "        new_likelihood /= length\n",
    "\n",
    "        if abs(new_likelihood - old_likelihood) < delta:\n",
    "            break\n",
    "\n",
    "        old_likelihood = new_likelihood\n",
    "\n",
    "    return model\n",
    "\n",
    "class Model(object):\n",
    "    \"\"\"\n",
    "    This class is an implementation of the Hidden Markov Model.\n",
    "    The instance of this class can be created by passing the given states,\n",
    "    symbols and optional probability matrices.\n",
    "    If any of the probability matrices are not given, the missing matrics\n",
    "    will be set to the initial uniform probability.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, states, symbols, start_prob=None, trans_prob=None, emit_prob=None):\n",
    "        self._states = set(states)\n",
    "        self._symbols = set(symbols)\n",
    "        self._start_prob = _normalize_prob(start_prob, self._states)\n",
    "        self._trans_prob = _normalize_prob_two_dim(trans_prob, self._states, self._states)\n",
    "        self._emit_prob = _normalize_prob_two_dim(emit_prob, self._states, self._symbols)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{name}({_states}, {_symbols}, {_start_prob}, {_trans_prob}, {_emit_prob})' \\\n",
    "            .format(name=self.__class__.__name__, **self.__dict__)\n",
    "\n",
    "    def states(self):\n",
    "        \"\"\" Return the state set of this model. \"\"\"\n",
    "        return set(self._states)\n",
    "\n",
    "    def states_number(self):\n",
    "        \"\"\" Return the number of states. \"\"\"\n",
    "        return len(self._states)\n",
    "\n",
    "    def symbols(self):\n",
    "        \"\"\" Return the symbol set of this model. \"\"\"\n",
    "        return set(self._symbols)\n",
    "\n",
    "    def symbols_number(self):\n",
    "        \"\"\" Return the number of symbols. \"\"\"\n",
    "        return len(self._symbols)\n",
    "\n",
    "    def start_prob(self, state):\n",
    "        \"\"\"\n",
    "        Return the start probability of the given state.\n",
    "        If `state` is not contained in the state set of this model, 0 is returned.\n",
    "        \"\"\"\n",
    "        if state not in self._states:\n",
    "            return 0\n",
    "        return self._start_prob[state]\n",
    "\n",
    "    def trans_prob(self, state_from, state_to):\n",
    "        \"\"\"\n",
    "        Return the probability that transition from state `state_from` to\n",
    "        state `state_to`.\n",
    "        If either the `state_from` or the `state_to` are not contained in the\n",
    "        state set of this model, 0 is returned.\n",
    "        \"\"\"\n",
    "        if state_from not in self._states or state_to not in self._states:\n",
    "            return 0\n",
    "        return self._trans_prob[state_from][state_to]\n",
    "\n",
    "    def emit_prob(self, state, symbol):\n",
    "        \"\"\"\n",
    "        Return the emission probability for `symbol` associated with the `state`.\n",
    "        If either the `state` or the `symbol` are not contained in this model,\n",
    "        0 is returned.\n",
    "        \"\"\"\n",
    "        if state not in self._states or symbol not in self._symbols:\n",
    "            return 0\n",
    "        return self._emit_prob[state][symbol]\n",
    "\n",
    "    def _forward(self, sequence):\n",
    "        sequence_length = len(sequence)\n",
    "        if sequence_length == 0:\n",
    "            return []\n",
    "\n",
    "        alpha = [{}]\n",
    "        for state in self._states:\n",
    "            alpha[0][state] = self.start_prob(state) * self.emit_prob(state, sequence[0])\n",
    "\n",
    "        for index in range(1, sequence_length):\n",
    "            alpha.append({})\n",
    "            for state_to in self._states:\n",
    "                prob = 0\n",
    "                for state_from in self._states:\n",
    "                    prob += alpha[index - 1][state_from] * \\\n",
    "                        self.trans_prob(state_from, state_to)\n",
    "                alpha[index][state_to] = prob * self.emit_prob(state_to, sequence[index])\n",
    "\n",
    "        return alpha\n",
    "\n",
    "    def _backward(self, sequence):\n",
    "        sequence_length = len(sequence)\n",
    "        if sequence_length == 0:\n",
    "            return []\n",
    "\n",
    "        beta = [{}]\n",
    "        for state in self._states:\n",
    "            beta[0][state] = 1\n",
    "\n",
    "        for index in range(sequence_length - 1, 0, -1):\n",
    "            beta.insert(0, {})\n",
    "            for state_from in self._states:\n",
    "                prob = 0\n",
    "                for state_to in self._states:\n",
    "                    prob += beta[1][state_to] * \\\n",
    "                        self.trans_prob(state_from, state_to) * \\\n",
    "                        self.emit_prob(state_to, sequence[index])\n",
    "                beta[0][state_from] = prob\n",
    "\n",
    "        return beta\n",
    "\n",
    "    def evaluate(self, sequence):\n",
    "        \"\"\"\n",
    "        Use the `forward algorithm\n",
    "        <http://en.wikipedia.org/wiki/Forward%E2%80%93backward_algorithm>`_\n",
    "        to evaluate the given sequence.\n",
    "        \"\"\"\n",
    "        length = len(sequence)\n",
    "        if length == 0:\n",
    "            return 0\n",
    "\n",
    "        prob = 0\n",
    "        alpha = self._forward(sequence)\n",
    "        for state in alpha[length - 1]:\n",
    "            prob += alpha[length - 1][state]\n",
    "\n",
    "        return prob\n",
    "\n",
    "    def decode(self, sequence):\n",
    "        \"\"\"\n",
    "        Decode the given sequence.\n",
    "        This method is an implementation of the\n",
    "        `Viterbi algorithm <http://en.wikipedia.org/wiki/Viterbi_algorithm>`_.\n",
    "        \"\"\"\n",
    "        sequence_length = len(sequence)\n",
    "        if sequence_length == 0:\n",
    "            return []\n",
    "\n",
    "        delta = {}\n",
    "        for state in self._states:\n",
    "            delta[state] = self.start_prob(state) * self.emit_prob(state, sequence[0])\n",
    "\n",
    "        pre = []\n",
    "        for index in range(1, sequence_length):\n",
    "            delta_bar = {}\n",
    "            pre_state = {}\n",
    "            for state_to in self._states:\n",
    "                max_prob = 0\n",
    "                max_state = None\n",
    "                for state_from in self._states:\n",
    "                    prob = delta[state_from] * self.trans_prob(state_from, state_to)\n",
    "                    if prob > max_prob:\n",
    "                        max_prob = prob\n",
    "                        max_state = state_from\n",
    "                delta_bar[state_to] = max_prob * self.emit_prob(state_to, sequence[index])\n",
    "                pre_state[state_to] = max_state\n",
    "            delta = delta_bar\n",
    "            pre.append(pre_state)\n",
    "\n",
    "        max_state = None\n",
    "        max_prob = 0\n",
    "        for state in self._states:\n",
    "            if delta[state] > max_prob:\n",
    "                max_prob = delta[state]\n",
    "                max_state = state\n",
    "\n",
    "        if max_state is None:\n",
    "            return []\n",
    "\n",
    "        result = [max_state]\n",
    "        for index in range(sequence_length - 1, 0, -1):\n",
    "            max_state = pre[index - 1][max_state]\n",
    "            result.insert(0, max_state)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def learn(self, sequence, smoothing=0):\n",
    "        \"\"\"\n",
    "        Use the given `sequence` to find the best state transition and\n",
    "        emission probabilities.\n",
    "        The optional `smoothing` argument (which is defaults to 0) is the\n",
    "        smoothing parameter of the\n",
    "        `additive smoothing <http://en.wikipedia.org/wiki/Additive_smoothing>`_\n",
    "        to avoid zero probability.\n",
    "        \"\"\"\n",
    "        length = len(sequence)\n",
    "        alpha = self._forward(sequence)\n",
    "        beta = self._backward(sequence)\n",
    "\n",
    "        gamma = []\n",
    "        for index in range(length):\n",
    "            prob_sum = 0\n",
    "            gamma.append({})\n",
    "            for state in self._states:\n",
    "                prob = alpha[index][state] * beta[index][state]\n",
    "                gamma[index][state] = prob\n",
    "                prob_sum += prob\n",
    "\n",
    "            if prob_sum == 0:\n",
    "                continue\n",
    "\n",
    "            for state in self._states:\n",
    "                gamma[index][state] /= prob_sum\n",
    "\n",
    "        xi = []\n",
    "        for index in range(length - 1):\n",
    "            prob_sum = 0\n",
    "            xi.append({})\n",
    "            for state_from in self._states:\n",
    "                xi[index][state_from] = {}\n",
    "                for state_to in self._states:\n",
    "                    prob = alpha[index][state_from] * beta[index + 1][state_to] * \\\n",
    "                        self.trans_prob(state_from, state_to) * \\\n",
    "                        self.emit_prob(state_to, sequence[index + 1])\n",
    "                    xi[index][state_from][state_to] = prob\n",
    "                    prob_sum += prob\n",
    "\n",
    "            if prob_sum == 0:\n",
    "                continue\n",
    "\n",
    "            for state_from in self._states:\n",
    "                for state_to in self._states:\n",
    "                    xi[index][state_from][state_to] /= prob_sum\n",
    "\n",
    "        states_number = len(self._states)\n",
    "        symbols_number = len(self._symbols)\n",
    "        for state in self._states:\n",
    "            # update start probability\n",
    "            self._start_prob[state] = \\\n",
    "                (smoothing + gamma[0][state]) / (1 + states_number * smoothing)\n",
    "\n",
    "            # update transition probability\n",
    "            gamma_sum = 0\n",
    "            for index in range(length - 1):\n",
    "                gamma_sum += gamma[index][state]\n",
    "\n",
    "            if gamma_sum > 0:\n",
    "                denominator = gamma_sum + states_number * smoothing\n",
    "                for state_to in self._states:\n",
    "                    xi_sum = 0\n",
    "                    for index in range(length - 1):\n",
    "                        xi_sum += xi[index][state][state_to]\n",
    "                    self._trans_prob[state][state_to] = (smoothing + xi_sum) / denominator\n",
    "            else:\n",
    "                for state_to in self._states:\n",
    "                    self._trans_prob[state][state_to] = 0\n",
    "\n",
    "            # update emission probability\n",
    "            gamma_sum += gamma[length - 1][state]\n",
    "            emit_gamma_sum = {}\n",
    "            for symbol in self._symbols:\n",
    "                emit_gamma_sum[symbol] = 0\n",
    "\n",
    "            for index in range(length):\n",
    "                emit_gamma_sum[sequence[index]] += gamma[index][state]\n",
    "\n",
    "            if gamma_sum > 0:\n",
    "                denominator = gamma_sum + symbols_number * smoothing\n",
    "                for symbol in self._symbols:\n",
    "                    self._emit_prob[state][symbol] = \\\n",
    "                        (smoothing + emit_gamma_sum[symbol]) / denominator\n",
    "            else:\n",
    "                for symbol in self._symbols:\n",
    "                    self._emit_prob[state][symbol] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c42e78c1-7c28-40a8-9934-d9756474d67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026600000000000013\n",
      "['hot', 'cold', 'hot']\n"
     ]
    }
   ],
   "source": [
    "states = ('hot', 'cold')\n",
    "symbols = ('1', '2', '3')\n",
    "\n",
    "start_prob = {\n",
    "    'hot' : 0.8,\n",
    "    'cold' : 0.2\n",
    "}\n",
    "\n",
    "trans_prob = {\n",
    "    'hot': { 'hot' : 0.6, 'cold' : 0.4 },\n",
    "    'cold': { 'hot' : 0.4, 'cold' : 0.6 }\n",
    "}\n",
    "\n",
    "emit_prob = {\n",
    "    'hot': { '1' : 0.2, '2' : 0.4, '3' : 0.4 },\n",
    "    'cold': { '1' : 0.5, '2' : 0.4, '3' : 0.1 }\n",
    "}\n",
    "\n",
    "model = Model(states, symbols, start_prob, trans_prob, emit_prob)\n",
    "sequence = ['3', '1', '3']\n",
    "print(model.evaluate(sequence)) # Likelihood 계산\n",
    "print(model.decode(sequence)) # 최적상태열 추정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accd95d3-dcc8-4e3a-8b4d-fb610abc1544",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
